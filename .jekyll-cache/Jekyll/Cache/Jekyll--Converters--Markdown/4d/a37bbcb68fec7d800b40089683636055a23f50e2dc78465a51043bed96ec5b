I"Ì
<h3 id="project-description">Project Description</h3>

<p>This is a completely custom implementation of the Mandelbrot Set visualization with interactive user zoom/pan using a mouse, on the Intel/Altera DE1-SoC Cyclone V FPGA board for VGA output on a 640x480 monitor. It incoporates medium-grained parallelization by dividing the screen into discrete tasks for each Mandelbrot solver, which speeds up the solution significantly. The final frequency that we could run the whole design was 75 Mhz, utilizing 100% of the FPGA resources. See data below for acceleration results. This was compared against dynamic parallelism using an ad hoc dispatching algorithm, and we found that the static task dispatching worked better because the dynamic dispatchingâ€™s calculation overhead outweighed the small amount of extra speed-up due to better parallel utilization. It is also worth mentioning that we used 4.23 fixed point for all imaginary calculations.</p>

<p>We compiled various .sof files that can be directly loaded into the DE1-SoCâ€™s FPGA with varying amount of parallelism, which are located in the upper most FPGA design directory  in my Github repo.</p>

<p>The number of iterations for the Mandelbrot algorithm can be dynamically selected in system runtime with the DE1-SoCâ€™s 10 switches, which represent the binary encoding for that number, range 0 to 1024. The color scheme is a custom implemented version of Alteraâ€™s VGA Subsystem University Graphics IP, which resulted in a high constrast and detailed visualization that emphasizes the red tone.</p>

<h3 id="challenges-and-accomplishments">Challenges and Accomplishments</h3>

<p>This project was done on a tight timeline of 4 weeks. There were many functionalities that had to be built from the ground up, such as motion control, face tracking, and interactive behavior. This was made more difficult by the fact that the computation was heavily restricted to a Raspberry Pi. Our development process consisted of building each modular function separately and tested in an isolated routine, then integrating the functionalities one-by-one. In the end, we built a multi-threaded python application, structured like an operating system to simultaneously handle multiple external signals. In terms of hardware, it was all custom built, and thankfully most of the robot arm was available from another ongoing project. However, it still required some design ingenuity to package the components elegantly, and for the entire module to come together as an interactive display. The website that we built to summarize the project in report form can be found <a href="https://courses.ece.cornell.edu/ece5990/ECE5725_Fall2019_Projects/Dec_04_Demo/Pixar_Lamp/Website/index.html#" target="_blank">here</a>.</p>
:ET